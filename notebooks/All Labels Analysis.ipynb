{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vegas - All Excerpts - 7_15_2019.xlsx_sentences_tfidf_cv_results_labels.csv',\n",
       " 'Isla Vista - All Excerpts - 1_2_2019.xlsx_sentences_tfidf_cv_results_labels.csv',\n",
       " 'Marysville - All Excerpts - Final - 1_2_2019.xlsx_excerpts_tfidf_cv_results_labels.csv',\n",
       " 'Newtown - All Excerpts - 1-2-2019.xlsx_excerpts_tfidf_cv_results_labels.csv',\n",
       " 'Orlando - All Excerpts - 7_15_2019.xlsx_sentences_tfidf_cv_results_labels.csv',\n",
       " 'Charleston - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv',\n",
       " 'Vegas - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv',\n",
       " 'Isla Vista - All Excerpts - 1_2_2019.xlsx_excerpts_tfidf_cv_results_labels.csv',\n",
       " 'Charleston - All Excerpts - 7_15_2019.xlsx_sentences_tfidf_cv_results_labels.csv',\n",
       " 'Orlando - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv',\n",
       " 'San Bernardino - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "path = 'classifier_cv_results/'\n",
    "file_names = os.listdir(path)\n",
    "[file_name for file_name in file_names if 'labels' in file_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Based Results For Each Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vegas - All Excerpts - 7_15_2019.xlsx_sentences_tfidf_cv_results_labels.csv\n",
      "Isla Vista - All Excerpts - 1_2_2019.xlsx_sentences_tfidf_cv_results_labels.csv\n",
      "Orlando - All Excerpts - 7_15_2019.xlsx_sentences_tfidf_cv_results_labels.csv\n",
      "Charleston - All Excerpts - 7_15_2019.xlsx_sentences_tfidf_cv_results_labels.csv\n"
     ]
    }
   ],
   "source": [
    "sentence_results_df = pd.DataFrame()\n",
    "\n",
    "for file_name in file_names:\n",
    "    if 'sentences' in file_name and 'labels' in file_name:\n",
    "        print(file_name)\n",
    "        event_df = pd.read_csv(path+file_name)\n",
    "        event_df['event'] = file_name.split(' - ')[0]        \n",
    "        sentence_results_df = pd.concat([sentence_results_df, event_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sentence_results_df.loc[:, ['label', 'event', 'vectorizer', 'classifier', \n",
    "                                 'recall', 'precision', 'fscore',\n",
    "                                 'num_test_exs', 'num_train_exs']]\n",
    "df_cv_mean = df.groupby(['label', 'event', 'vectorizer', 'classifier']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d640d73031fa4510a0639a1da08aa069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='event', description='column1'), Text(value='label', description='column2'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df_cv_mean.reset_index().groupby(['label', \n",
    "                                     'event']).max().reset_index().loc[:, ['fscore', 'recall', 'precision', \n",
    "                                                                            'label', 'event',\n",
    "                                                                            'num_test_exs', 'num_train_exs']]\n",
    "labels = ['ALL']+list(set(df['label']))\n",
    "events = ['ALL']+list(set(df['event']))\n",
    "@interact\n",
    "def show_results(column1='event', column2='label',\n",
    "                 column3='num_test_exs', column4='num_train_exs',\n",
    "                 event=events, label = labels, \n",
    "                 num_test = (0,50,1), num_train = (0,100,1)):\n",
    "    \n",
    "    df_len = df.shape[0]\n",
    "    num_test_filt = df[column3] > num_test\n",
    "    num_train_filt = df[column4] > num_train\n",
    "    event_filt =[(df.loc[i, column1] == event) or (event == 'ALL') for i in range(df_len)]\n",
    "    label_filt =[(df.loc[i, column2] == label) or (label == 'ALL') for i in range(df_len)]\n",
    "    final_filt = [num_test_filt[i]&num_train_filt[i]&event_filt[i]&label_filt[i] for i in range(df_len)]\n",
    "    \n",
    "    return df.loc[final_filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excerpt Based Results for Each Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marysville - All Excerpts - Final - 1_2_2019.xlsx_excerpts_tfidf_cv_results_labels.csv\n",
      "Newtown - All Excerpts - 1-2-2019.xlsx_excerpts_tfidf_cv_results_labels.csv\n",
      "Charleston - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv\n",
      "Vegas - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv\n",
      "Isla Vista - All Excerpts - 1_2_2019.xlsx_excerpts_tfidf_cv_results_labels.csv\n",
      "Orlando - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv\n",
      "San Bernardino - All Excerpts - 7_15_2019.xlsx_excerpts_tfidf_cv_results_labels.csv\n"
     ]
    }
   ],
   "source": [
    "excerpt_results_df = pd.DataFrame()\n",
    "\n",
    "for file_name in file_names:\n",
    "    if 'sentences' not in file_name and 'labels' in file_name:\n",
    "        print(file_name)\n",
    "        event_df = pd.read_csv(path+file_name)\n",
    "        event_df['event'] = file_name.split(' - ')[0]        \n",
    "        excerpt_results_df = pd.concat([excerpt_results_df, event_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = excerpt_results_df.loc[:, ['label', 'event', 'vectorizer', 'classifier', \n",
    "                                'recall', 'precision', 'fscore',\n",
    "                                'num_test_exs', 'num_train_exs']]\n",
    "df_cv_mean = df.groupby(['label', 'event', 'vectorizer', 'classifier']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0fd998437f406e98284264f7d8a344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='event', description='column1'), Text(value='label', description='column2'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ex = df_cv_mean.reset_index().groupby(['label', \n",
    "                                     'event']).max().reset_index().loc[:, ['fscore', 'recall', 'precision', \n",
    "                                                                           'label', 'event',\n",
    "                                                                            'num_test_exs', 'num_train_exs']]\n",
    "labels = ['ALL']+list(set(df_ex['label']))\n",
    "events = ['ALL']+list(set(df_ex['event']))\n",
    "@interact\n",
    "def show_results(column1='event', column2='label',\n",
    "                 column3='num_test_exs', column4='num_train_exs',\n",
    "                 event=events, label = labels, \n",
    "                 num_test = (0,50,1), num_train = (0,100,1)):\n",
    "    \n",
    "    df_len = df_ex.shape[0]\n",
    "    num_test_filt = df_ex[column3] > num_test\n",
    "    num_train_filt = df_ex[column4] > num_train\n",
    "    event_filt =[(df_ex.loc[i, column1] == event) or (event == 'ALL') for i in range(df_len)]\n",
    "    label_filt =[(df_ex.loc[i, column2] == label) or (label == 'ALL') for i in range(df_len)]\n",
    "    final_filt = [num_test_filt[i]&num_train_filt[i]&event_filt[i]&label_filt[i] for i in range(df_len)]\n",
    "    \n",
    "    return df_ex.loc[final_filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Events\n",
    "\n",
    "### Sentence Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_results_df = pd.DataFrame()\n",
    "\n",
    "for file_name in file_names:\n",
    "    if 'sentences' in file_name and 'labels' in file_name and 'fulldata' in file_name:\n",
    "        event_df = pd.read_csv(path+file_name)\n",
    "        event_df['event'] = file_name.split(' - ')[0]        \n",
    "        sentence_results_df = pd.concat([sentence_results_df, event_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sentence_results_df.loc[:, ['label', 'event', 'vectorizer', 'classifier', 'recall', 'precision', 'fscore']]\n",
    "df_cv_mean = df.groupby(['label', 'event', 'vectorizer', 'classifier']).mean()\n",
    "df_results = df_cv_mean.reset_index().groupby(['label', \n",
    "                                     'event']).max().reset_index().loc[:, ['fscore', 'recall', \n",
    "                                                                            'precision', 'label', 'event']]\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_results_df = pd.DataFrame()\n",
    "\n",
    "for file_name in file_names:\n",
    "    if 'sentences' not in file_name and 'labels' in file_name and 'fulldata' in file_name:\n",
    "        print(file_name)\n",
    "        event_df = pd.read_csv(path+file_name)      \n",
    "        event_results_df = pd.concat([event_results_df, event_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = event_results_df.loc[:, ['label', 'event', 'vectorizer', 'classifier', 'recall', 'precision', 'fscore']]\n",
    "df_cv_mean = df.groupby(['label', 'event', 'vectorizer', 'classifier']).mean()\n",
    "df_results = df_cv_mean.reset_index().groupby(['label', \n",
    "                                     'event']).max().reset_index().loc[:, ['fscore', 'recall', \n",
    "                                                                            'precision', 'label', 'event']]\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
